---
description: "Tailscale operator patterns and conventions for secure, private loadbalancer functionality in Kubernetes with GitOps"
alwaysApply: false
---
# Tailscale Operator Implementation Guide

## Overview
The Tailscale operator provides secure, private loadbalancer functionality for exposing Kubernetes services to your tailnet using GitOps with Flux.

## Key Files and Structure

### Core Configuration
- **HelmRelease**: [kubernetes/apps/network/tailscale/app/helmrelease.yaml](mdc:kubernetes/apps/network/tailscale/app/helmrelease.yaml)
  - Uses official Tailscale Helm chart from `https://pkgs.tailscale.com/helmcharts`
  - OAuth credentials configured via `valuesFrom` with Secret reference
  - No version pinning - uses latest stable releases

- **ProxyClass**: [kubernetes/apps/network/tailscale/app/proxyclass.yaml](mdc:kubernetes/apps/network/tailscale/app/proxyclass.yaml)
  - Cluster-scoped resource (no namespace)
  - Customizes proxy pod configurations
  - Use `spec.pod.tailscaleContainer` structure

- **Secrets**: [kubernetes/apps/network/tailscale/app/secret.sops.yaml](mdc:kubernetes/apps/network/tailscale/app/secret.sops.yaml)
  - Must be encrypted using SOPS before committing
  - Contains OAuth client ID and secret
  - Use `sops --encrypt -i` for in-place encryption

### Flux Integration
- **Kustomization**: [kubernetes/apps/network/tailscale/app/kustomization.yaml](mdc:kubernetes/apps/network/tailscale/app/kustomization.yaml)
- **Flux Kustomization**: [kubernetes/apps/network/tailscale/ks.yaml](mdc:kubernetes/apps/network/tailscale/ks.yaml)
- **Network Integration**: [kubernetes/apps/network/kustomization.yaml](mdc:kubernetes/apps/network/kustomization.yaml)

## Usage Patterns

### LoadBalancer Service
```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app
spec:
  type: LoadBalancer
  loadBalancerClass: tailscale
  ports:
    - port: 80
      targetPort: 8080
```

### Service Annotation
```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app
  annotations:
    tailscale.com/expose: "true"
    tailscale.com/tags: "tag:web,tag:internal"
    tailscale.com/hostname: "my-custom-name"
spec:
  type: ClusterIP
```

### Ingress Resource
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-app
spec:
  ingressClassName: tailscale
  tls:
    - hosts:
        - my-app.your-tailnet.ts.net
```

## Configuration Best Practices

### OAuth Setup
1. Create OAuth client in Tailscale admin console
2. Required scopes: `Devices Core` (write), `Auth Keys` (write)
3. Tag: `tag:k8s-operator`
4. Update ACL policy with proper tag ownership

### Security Considerations
- All services exposed only to your tailnet (zero trust)
- Use tag-based access control
- OAuth credentials encrypted with SOPS
- Proxy pods run with minimal privileges

### Resource Management
- ProxyClass for customizing proxy configurations
- Resource limits: CPU 500m, Memory 512Mi
- Security context: non-root execution (UID 65534)

## Troubleshooting

### Common Issues
1. **OAuth Authentication Failed**: Verify client ID/secret and ACL policy
2. **Service Not Exposed**: Check operator health and annotations
3. **LoadBalancer Pending**: Ensure operator is running
4. **ProxyClass Not Found**: Verify cluster-scoped placement

### Debug Commands
```bash
# Check operator status
kubectl get pods -n network -l app.kubernetes.io/name=tailscale-operator

# View operator logs
kubectl logs -n network -l app.kubernetes.io/name=tailscale-operator

# Check service status
kubectl get service my-app -o wide

# Verify Tailscale nodes in admin console
# https://login.tailscale.com/admin/machines
```

## Maintenance

### Updates
- Operator updates automatically via Flux
- Helm chart from official Tailscale repository
- No manual version management required

### Monitoring
- Check operator pod health
- Monitor proxy pod creation
- Verify service exposure in Tailscale admin console

## Architecture Benefits

- **Native Kubernetes Integration**: Standard LoadBalancer/Service types
- **Zero Trust Networking**: Services only accessible within tailnet
- **GitOps Workflow**: Fully automated via Flux
- **MagicDNS**: Automatic DNS resolution for exposed services
- **Tag-based Access Control**: Fine-grained security management

## References
- [Official Documentation](https://tailscale.com/kb/1236/kubernetes-operator)
- [Cluster Ingress Guide](https://tailscale.com/kb/1439/kubernetes-operator-cluster-ingress)
- [ProxyClass Customization](https://tailscale.com/kb/1445/kubernetes-operator-customization)
- [Helm Charts](https://pkgs.tailscale.com/helmcharts)
# Tailscale Operator Implementation Guide

## Overview
The Tailscale operator provides secure, private loadbalancer functionality for exposing Kubernetes services to your tailnet using GitOps with Flux.

## Key Files and Structure

### Core Configuration
- **HelmRelease**: [kubernetes/apps/network/tailscale/app/helmrelease.yaml](mdc:kubernetes/apps/network/tailscale/app/helmrelease.yaml)
  - Uses official Tailscale Helm chart from `https://pkgs.tailscale.com/helmcharts`
  - OAuth credentials configured via `valuesFrom` with Secret reference
  - No version pinning - uses latest stable releases

- **ProxyClass**: [kubernetes/apps/network/tailscale/app/proxyclass.yaml](mdc:kubernetes/apps/network/tailscale/app/proxyclass.yaml)
  - Cluster-scoped resource (no namespace)
  - Customizes proxy pod configurations
  - Use `spec.pod.tailscaleContainer` structure

- **Secrets**: [kubernetes/apps/network/tailscale/app/secret.sops.yaml](mdc:kubernetes/apps/network/tailscale/app/secret.sops.yaml)
  - Must be encrypted using SOPS before committing
  - Contains OAuth client ID and secret
  - Use `sops --encrypt -i` for in-place encryption

### Flux Integration
- **Kustomization**: [kubernetes/apps/network/tailscale/app/kustomization.yaml](mdc:kubernetes/apps/network/tailscale/app/kustomization.yaml)
- **Flux Kustomization**: [kubernetes/apps/network/tailscale/ks.yaml](mdc:kubernetes/apps/network/tailscale/ks.yaml)
- **Network Integration**: [kubernetes/apps/network/kustomization.yaml](mdc:kubernetes/apps/network/kustomization.yaml)

## Usage Patterns

### LoadBalancer Service
```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app
spec:
  type: LoadBalancer
  loadBalancerClass: tailscale
  ports:
    - port: 80
      targetPort: 8080
```

### Service Annotation
```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app
  annotations:
    tailscale.com/expose: "true"
    tailscale.com/tags: "tag:web,tag:internal"
    tailscale.com/hostname: "my-custom-name"
spec:
  type: ClusterIP
```

### Ingress Resource
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-app
spec:
  ingressClassName: tailscale
  tls:
    - hosts:
        - my-app.your-tailnet.ts.net
```

## Configuration Best Practices

### OAuth Setup
1. Create OAuth client in Tailscale admin console
2. Required scopes: `Devices Core` (write), `Auth Keys` (write)
3. Tag: `tag:k8s-operator`
4. Update ACL policy with proper tag ownership

### Security Considerations
- All services exposed only to your tailnet (zero trust)
- Use tag-based access control
- OAuth credentials encrypted with SOPS
- Proxy pods run with minimal privileges

### Resource Management
- ProxyClass for customizing proxy configurations
- Resource limits: CPU 500m, Memory 512Mi
- Security context: non-root execution (UID 65534)

## Troubleshooting

### Common Issues
1. **OAuth Authentication Failed**: Verify client ID/secret and ACL policy
2. **Service Not Exposed**: Check operator health and annotations
3. **LoadBalancer Pending**: Ensure operator is running
4. **ProxyClass Not Found**: Verify cluster-scoped placement

### Debug Commands
```bash
# Check operator status
kubectl get pods -n network -l app.kubernetes.io/name=tailscale-operator

# View operator logs
kubectl logs -n network -l app.kubernetes.io/name=tailscale-operator

# Check service status
kubectl get service my-app -o wide

# Verify Tailscale nodes in admin console
# https://login.tailscale.com/admin/machines
```

## Maintenance

### Updates
- Operator updates automatically via Flux
- Helm chart from official Tailscale repository
- No manual version management required

### Monitoring
- Check operator pod health
- Monitor proxy pod creation
- Verify service exposure in Tailscale admin console

## Architecture Benefits

- **Native Kubernetes Integration**: Standard LoadBalancer/Service types
- **Zero Trust Networking**: Services only accessible within tailnet
- **GitOps Workflow**: Fully automated via Flux
- **MagicDNS**: Automatic DNS resolution for exposed services
- **Tag-based Access Control**: Fine-grained security management

## References
- [Official Documentation](https://tailscale.com/kb/1236/kubernetes-operator)
- [Cluster Ingress Guide](https://tailscale.com/kb/1439/kubernetes-operator-cluster-ingress)
- [ProxyClass Customization](https://tailscale.com/kb/1445/kubernetes-operator-customization)
- [Helm Charts](https://pkgs.tailscale.com/helmcharts)
